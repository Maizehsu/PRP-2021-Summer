{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import tensorflow as tf  \n",
    "from tensorflow import keras  \n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization  \n",
    "from tensorflow.keras.layers import Activation, MaxPooling2D  \n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import UpSampling2D  \n",
    "from tensorflow.keras.layers import Input, Flatten, Dense  \n",
    "from tensorflow.keras.models import Model \n",
    "import numpy as npdata\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_B_PATH_WIN = 'F:\\大学\\第40期PRP\\特征提取\\\\1_feature_analysis\\Intergated-DATASET-D.csv'\n",
    "PREPROCESS_PATH_WIN = 'F:/大学/第40期PRP/PRP 测试代码/CNN/congestion.csv'\n",
    "data_in = pd.read_csv(DATASET_B_PATH_WIN).drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_in.loc[data_in.date <= 20161105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-139, -110, 0, 29)\n"
     ]
    }
   ],
   "source": [
    "ROW_LIM_DOWN = int(data.row_id.min())\n",
    "ROW_LIM_UP = int(data.row_id.max() - 109)\n",
    "COL_LIM_DOWN = int(data.col_id.min())\n",
    "COL_LIM_UP = int(data.col_id.max() - 109)\n",
    "print((ROW_LIM_DOWN, ROW_LIM_UP, COL_LIM_DOWN, COL_LIM_UP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选定待处理的空间网格区域\n",
    "data = data.loc[(data.row_id >= ROW_LIM_DOWN)&(data.row_id <= ROW_LIM_UP) &(data.col_id >= COL_LIM_DOWN) & (data.col_id <= COL_LIM_UP)]\n",
    "# 将所有网格id转换成int型\n",
    "for c in ['row_id', 'col_id', 'time_id']:  \n",
    "    data[c] = data[c].astype(int)\n",
    "# 将date和id处理成正整数，然后排序\n",
    "data['date'] -= data['date'].min()\n",
    "data['row_id'] -= data['row_id'].min()\n",
    "data['col_id'] -= data['col_id'].min()\n",
    "data['time_id'] -= data['time_id'].min()\n",
    "data = data.sort_values(['date', 'row_id', 'col_id', 'time_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>col_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>aveSpeed</th>\n",
       "      <th>gridAcc</th>\n",
       "      <th>volume</th>\n",
       "      <th>speedStd</th>\n",
       "      <th>stopNum</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>15.571961</td>\n",
       "      <td>-2.323410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>10.679653</td>\n",
       "      <td>-0.098228</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>12.348424</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>9.483641</td>\n",
       "      <td>0.109564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.754410</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318101</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>265</td>\n",
       "      <td>9.276823</td>\n",
       "      <td>-0.714574</td>\n",
       "      <td>8</td>\n",
       "      <td>5.971452</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318102</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>266</td>\n",
       "      <td>8.506305</td>\n",
       "      <td>-0.687411</td>\n",
       "      <td>14</td>\n",
       "      <td>5.056376</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318103</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>267</td>\n",
       "      <td>7.579736</td>\n",
       "      <td>-0.116602</td>\n",
       "      <td>11</td>\n",
       "      <td>5.190623</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318104</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>268</td>\n",
       "      <td>10.921124</td>\n",
       "      <td>-0.013864</td>\n",
       "      <td>15</td>\n",
       "      <td>2.878470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318105</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>269</td>\n",
       "      <td>8.738036</td>\n",
       "      <td>-0.457128</td>\n",
       "      <td>13</td>\n",
       "      <td>4.861093</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318106 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        row_id  col_id  time_id   aveSpeed   gridAcc  volume  speedStd  \\\n",
       "0            0       5        9  15.571961 -2.323410       1  0.000000   \n",
       "1            0       5       12  10.679653 -0.098228       1  0.000000   \n",
       "2            0       5       15  12.348424  0.018499       2  1.345171   \n",
       "3            0       5       18   9.483641  0.109564       1  0.000000   \n",
       "4            0       5       24  12.754410 -0.000014       1  0.000000   \n",
       "...        ...     ...      ...        ...       ...     ...       ...   \n",
       "318101      29      29      265   9.276823 -0.714574       8  5.971452   \n",
       "318102      29      29      266   8.506305 -0.687411      14  5.056376   \n",
       "318103      29      29      267   7.579736 -0.116602      11  5.190623   \n",
       "318104      29      29      268  10.921124 -0.013864      15  2.878470   \n",
       "318105      29      29      269   8.738036 -0.457128      13  4.861093   \n",
       "\n",
       "         stopNum  date  \n",
       "0       0.000000     0  \n",
       "1       0.000000     0  \n",
       "2       0.000000     0  \n",
       "3       0.000000     0  \n",
       "4       0.000000     0  \n",
       "...          ...   ...  \n",
       "318101  1.125000     4  \n",
       "318102  0.928571     4  \n",
       "318103  2.363636     4  \n",
       "318104  0.000000     4  \n",
       "318105  0.615385     4  \n",
       "\n",
       "[318106 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_recovery(df_, cols=[], lens=[]):\n",
    "    df = df_.copy()\n",
    "    lcols = len(cols)\n",
    "    llens = len(lens)\n",
    "    \n",
    "    if lcols != llens: # 确保输入的网格名称和网格长度信息的长度一致\n",
    "        raise ValueError(f'Lengths of cols ({lcols}) and lens ({llens}) mismatch.')\n",
    "    \n",
    "    recovery_df = None\n",
    "    for c, l in zip(cols, lens):\n",
    "        tmp_df = pd.DataFrame({c:range(l)})\n",
    "        tmp_df['flag'] = True\n",
    "        if recovery_df is None:\n",
    "            recovery_df = tmp_df.copy()\n",
    "        else:\n",
    "            recovery_df = recovery_df.merge(tmp_df, 'left', 'flag')\n",
    "    \n",
    "    del recovery_df['flag']\n",
    "    \n",
    "    df = pd.merge(recovery_df, df, on=['date','row_id', 'col_id', 'time_id'], how='outer')\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NROWS = int(data.row_id.max() - data.row_id.min() + 1) # 空间网格行数  \n",
    "NCOLS = int(data.col_id.max() - data.col_id.min() + 1) # 空间网格列数  \n",
    "NTIME = int(data.time_id.max() - data.time_id.min() + 1) # 时间网格数  \n",
    "NDATE = 5 # 日期网格数\n",
    "time_density = 6\n",
    "space_density = 2\n",
    "win_s = 10\n",
    "win_t = 2\n",
    "win_T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = grid_recovery(data, ['date', 'row_id', 'col_id', 'time_id'], [NDATE, NROWS, NCOLS, NTIME])  \n",
    "for c in ['volume', 'stopNum']:  \n",
    "    data[c] = data[c].astype(int) # 调整数据类型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>row_id</th>\n",
       "      <th>col_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>aveSpeed</th>\n",
       "      <th>gridAcc</th>\n",
       "      <th>volume</th>\n",
       "      <th>speedStd</th>\n",
       "      <th>stopNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214995</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>265</td>\n",
       "      <td>9.276823</td>\n",
       "      <td>-0.714574</td>\n",
       "      <td>8</td>\n",
       "      <td>5.971452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214996</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>266</td>\n",
       "      <td>8.506305</td>\n",
       "      <td>-0.687411</td>\n",
       "      <td>14</td>\n",
       "      <td>5.056376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214997</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>267</td>\n",
       "      <td>7.579736</td>\n",
       "      <td>-0.116602</td>\n",
       "      <td>11</td>\n",
       "      <td>5.190623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214998</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>268</td>\n",
       "      <td>10.921124</td>\n",
       "      <td>-0.013864</td>\n",
       "      <td>15</td>\n",
       "      <td>2.878470</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214999</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>269</td>\n",
       "      <td>8.738036</td>\n",
       "      <td>-0.457128</td>\n",
       "      <td>13</td>\n",
       "      <td>4.861093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  row_id  col_id  time_id   aveSpeed   gridAcc  volume  speedStd  \\\n",
       "0           0       0       0        0   0.000000  0.000000       0  0.000000   \n",
       "1           0       0       0        1   0.000000  0.000000       0  0.000000   \n",
       "2           0       0       0        2   0.000000  0.000000       0  0.000000   \n",
       "3           0       0       0        3   0.000000  0.000000       0  0.000000   \n",
       "4           0       0       0        4   0.000000  0.000000       0  0.000000   \n",
       "...       ...     ...     ...      ...        ...       ...     ...       ...   \n",
       "1214995     4      29      29      265   9.276823 -0.714574       8  5.971452   \n",
       "1214996     4      29      29      266   8.506305 -0.687411      14  5.056376   \n",
       "1214997     4      29      29      267   7.579736 -0.116602      11  5.190623   \n",
       "1214998     4      29      29      268  10.921124 -0.013864      15  2.878470   \n",
       "1214999     4      29      29      269   8.738036 -0.457128      13  4.861093   \n",
       "\n",
       "         stopNum  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "1214995        1  \n",
       "1214996        0  \n",
       "1214997        2  \n",
       "1214998        0  \n",
       "1214999        0  \n",
       "\n",
       "[1215000 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 30, 30, 270]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[NDATE, NROWS, NCOLS, NTIME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当前网格数太多了，可以进一步合并\n",
    "data['hourid'] = data['time_id'] // time_density # 合并时间网格  \n",
    "data['new_rowid'] = data.row_id // space_density# 合并空间网格  \n",
    "data['new_colid'] = data.col_id //space_density\n",
    "congest = data.groupby( # 计算合并网格后各网格的流量  \n",
    "    ['date', 'new_rowid', 'new_colid', 'hourid']).aveSpeed.mean().reset_index()  \n",
    "congest.columns = ['date', 'row_id', 'col_id', 'hourid', 'aveSpeed'] \n",
    "\n",
    "TIME_UNIT = data.groupby('hourid').size().count() # 每个date里所包含的hourid的数量\n",
    "from math import ceil\n",
    "\n",
    "congest_pivot = congest.pivot_table(  \n",
    "    index=['date', 'hourid', 'row_id'],  \n",
    "    columns='col_id',  \n",
    "    values='aveSpeed').fillna(0).reset_index() # 网格转换  \n",
    "congest_pivot['timeseq'] = congest_pivot['date'] * TIME_UNIT + congest_pivot['hourid'] # 时间序号  \n",
    "congest_pivot_np = congest_pivot[[c for c in range(ceil(NCOLS/space_density))]].values # 提取速度数值\n",
    "\n",
    "def gen_movie(df, win_t, win_T, nrows=ceil(NROWS/space_density), ncols=ceil(NCOLS/space_density), win_s=win_s, ntime=NDATE*TIME_UNIT):  #注意：win_s必须得小于nrows,ncols!!!\n",
    "    n_i = nrows - win_s + 1   \n",
    "    n_j = ncols - win_s + 1   \n",
    "    piece = []  \n",
    "    for t in range(3*TIME_UNIT - 1, ntime):   #第一天末尾的hourid索引实际上是TIME_UNIT - 1，而不是TIME_UNIT\n",
    "        for i in range(n_i):  \n",
    "            for j in range(n_j):  \n",
    "                # 周期特征  \n",
    "                prd_piece = df[t-(win_T*TIME_UNIT - 1) : t - (TIME_UNIT - 1) + 1: TIME_UNIT, i:i+win_s, j:j+win_s]  \n",
    "                # 邻近特征  \n",
    "                nbr_piece = df[t-win_t:t+1, i:i+win_s, j:j+win_s]  \n",
    "                piece.append(np.vstack([prd_piece, nbr_piece]))  \n",
    "    return np.stack(piece)  \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层\n",
    "def conv_layer(inputs,  \n",
    "             num_filters=16,  \n",
    "             kernel_size=3,  \n",
    "             strides=1,  \n",
    "             data_format='channels_first',  \n",
    "             activation='relu',  \n",
    "             batch_normalization=True,  \n",
    "             maxpooling=True,  \n",
    "             pool_size=2,  \n",
    "             pool_strides=2):  \n",
    "    conv = Conv2D(num_filters,  \n",
    "                 kernel_size=kernel_size,  \n",
    "                 strides=strides,  \n",
    "                 padding='same',  \n",
    "                 data_format=data_format,  \n",
    "                 kernel_regularizer=l2(1e-4))  \n",
    "    x = conv(inputs)  # 卷积\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x) # 批归一化\n",
    "    if activation is not None:\n",
    "        x = Activation(activation)(x) # 激活函数\n",
    "    if maxpooling:\n",
    "        x = MaxPooling2D(pool_size=pool_size,  \n",
    "                        strides=pool_strides,  \n",
    "                        data_format=data_format,  \n",
    "                        padding='same')(x) # 池化\n",
    "    return x\n",
    "\n",
    "def upsample_layer(inputs,  \n",
    "                up_size=2,  \n",
    "                interpolation='nearest',  \n",
    "                data_format='channels_first'):\n",
    "    upsample = UpSampling2D(size=up_size,\n",
    "                    data_format=data_format,\n",
    "                    interpolation=interpolation)  \n",
    "    x = upsample(inputs) # 上采样\n",
    "    return x\n",
    "\n",
    "def cnn_model(input_shape):  \n",
    "    inputs = Input(shape=input_shape)  \n",
    "    x = conv_layer(inputs, 16, pool_strides=1)  \n",
    "    x = conv_layer(x, 32, pool_strides=1)  \n",
    "    x = conv_layer(x, 32, pool_strides=1)  \n",
    "    x = conv_layer(x, 16)  \n",
    "    x = upsample_layer(x, 2)  \n",
    "    x = conv_layer(x, 1, maxpooling=False)  \n",
    "    y = Flatten(data_format='channels_first')(x)  \n",
    "    y = Dense(128, activation='relu')(y)  \n",
    "    y = Dense(128, activation='relu')(y)  \n",
    "    outputs = Dense(100, activation='relu')(y)  \n",
    "    # 建立模型  \n",
    "    model = Model(inputs=inputs, outputs=outputs)  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE_PER_HOUR = (ceil(NROWS/space_density) - win_s + 1) * (ceil(NCOLS/space_density) - win_s + 1) # 计算数据增强（裁剪）之后，一个hourid内的数据数量\n",
    "N_SAMPLES_LAST_DAY = TIME_UNIT * N_SAMPLE_PER_HOUR #计算最后一天的样本（数据）量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = [1,2,3,4,5,6,7,8,9,10]\n",
    "Batch_size = [32,64,96,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_records = []\n",
    "ex_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 1324 samples, validate on 332 samples\n",
      "Epoch 1/50\n",
      "1324/1324 [==============================] - 3s 2ms/sample - loss: 0.0453 - mean_absolute_error: 0.1306 - mean_squared_error: 0.0372 - val_loss: 0.0542 - val_mean_absolute_error: 0.1521 - val_mean_squared_error: 0.0464\n",
      "Epoch 2/50\n",
      "1324/1324 [==============================] - 0s 264us/sample - loss: 0.0348 - mean_absolute_error: 0.1154 - mean_squared_error: 0.0273 - val_loss: 0.0509 - val_mean_absolute_error: 0.1485 - val_mean_squared_error: 0.0437\n",
      "Epoch 3/50\n",
      "1324/1324 [==============================] - 0s 262us/sample - loss: 0.0294 - mean_absolute_error: 0.1044 - mean_squared_error: 0.0225 - val_loss: 0.0490 - val_mean_absolute_error: 0.1463 - val_mean_squared_error: 0.0423\n",
      "Epoch 4/50\n",
      "1324/1324 [==============================] - 0s 282us/sample - loss: 0.0252 - mean_absolute_error: 0.0925 - mean_squared_error: 0.0187 - val_loss: 0.0469 - val_mean_absolute_error: 0.1435 - val_mean_squared_error: 0.0407\n",
      "Epoch 5/50\n",
      "1324/1324 [==============================] - 0s 271us/sample - loss: 0.0219 - mean_absolute_error: 0.0826 - mean_squared_error: 0.0158 - val_loss: 0.0437 - val_mean_absolute_error: 0.1382 - val_mean_squared_error: 0.0378\n",
      "Epoch 6/50\n",
      "1324/1324 [==============================] - 0s 307us/sample - loss: 0.0190 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0133 - val_loss: 0.0387 - val_mean_absolute_error: 0.1288 - val_mean_squared_error: 0.0332\n",
      "Epoch 7/50\n",
      "1324/1324 [==============================] - 0s 286us/sample - loss: 0.0167 - mean_absolute_error: 0.0666 - mean_squared_error: 0.0113 - val_loss: 0.0346 - val_mean_absolute_error: 0.1205 - val_mean_squared_error: 0.0293\n",
      "Epoch 8/50\n",
      "1324/1324 [==============================] - 0s 299us/sample - loss: 0.0151 - mean_absolute_error: 0.0609 - mean_squared_error: 0.0100 - val_loss: 0.0293 - val_mean_absolute_error: 0.1089 - val_mean_squared_error: 0.0243\n",
      "Epoch 9/50\n",
      "1324/1324 [==============================] - 0s 265us/sample - loss: 0.0140 - mean_absolute_error: 0.0570 - mean_squared_error: 0.0091 - val_loss: 0.0242 - val_mean_absolute_error: 0.0968 - val_mean_squared_error: 0.0194\n",
      "Epoch 10/50\n",
      "1324/1324 [==============================] - 0s 259us/sample - loss: 0.0128 - mean_absolute_error: 0.0536 - mean_squared_error: 0.0081 - val_loss: 0.0203 - val_mean_absolute_error: 0.0862 - val_mean_squared_error: 0.0158\n",
      "Epoch 11/50\n",
      "1324/1324 [==============================] - 0s 265us/sample - loss: 0.0122 - mean_absolute_error: 0.0514 - mean_squared_error: 0.0077 - val_loss: 0.0178 - val_mean_absolute_error: 0.0783 - val_mean_squared_error: 0.0134\n",
      "Epoch 12/50\n",
      "1324/1324 [==============================] - 0s 290us/sample - loss: 0.0117 - mean_absolute_error: 0.0499 - mean_squared_error: 0.0074 - val_loss: 0.0163 - val_mean_absolute_error: 0.0732 - val_mean_squared_error: 0.0120\n",
      "Epoch 13/50\n",
      "1324/1324 [==============================] - 0s 282us/sample - loss: 0.0113 - mean_absolute_error: 0.0485 - mean_squared_error: 0.0071 - val_loss: 0.0142 - val_mean_absolute_error: 0.0652 - val_mean_squared_error: 0.0101\n",
      "Epoch 14/50\n",
      "1324/1324 [==============================] - 0s 271us/sample - loss: 0.0109 - mean_absolute_error: 0.0471 - mean_squared_error: 0.0069 - val_loss: 0.0136 - val_mean_absolute_error: 0.0635 - val_mean_squared_error: 0.0097\n",
      "Epoch 15/50\n",
      "1324/1324 [==============================] - 0s 265us/sample - loss: 0.0105 - mean_absolute_error: 0.0460 - mean_squared_error: 0.0067 - val_loss: 0.0132 - val_mean_absolute_error: 0.0620 - val_mean_squared_error: 0.0095\n",
      "Epoch 16/50\n",
      "1324/1324 [==============================] - 0s 280us/sample - loss: 0.0103 - mean_absolute_error: 0.0456 - mean_squared_error: 0.0066 - val_loss: 0.0128 - val_mean_absolute_error: 0.0607 - val_mean_squared_error: 0.0091\n",
      "Epoch 17/50\n",
      "1324/1324 [==============================] - 0s 257us/sample - loss: 0.0101 - mean_absolute_error: 0.0449 - mean_squared_error: 0.0065 - val_loss: 0.0126 - val_mean_absolute_error: 0.0606 - val_mean_squared_error: 0.0091\n",
      "Epoch 18/50\n",
      "1324/1324 [==============================] - 0s 320us/sample - loss: 0.0098 - mean_absolute_error: 0.0443 - mean_squared_error: 0.0064 - val_loss: 0.0121 - val_mean_absolute_error: 0.0588 - val_mean_squared_error: 0.0087\n",
      "Epoch 19/50\n",
      "1324/1324 [==============================] - 0s 305us/sample - loss: 0.0096 - mean_absolute_error: 0.0438 - mean_squared_error: 0.0063 - val_loss: 0.0119 - val_mean_absolute_error: 0.0582 - val_mean_squared_error: 0.0086\n",
      "Epoch 20/50\n",
      "1324/1324 [==============================] - 0s 270us/sample - loss: 0.0094 - mean_absolute_error: 0.0433 - mean_squared_error: 0.0062 - val_loss: 0.0117 - val_mean_absolute_error: 0.0577 - val_mean_squared_error: 0.0086\n",
      "Epoch 21/50\n",
      "1324/1324 [==============================] - 0s 303us/sample - loss: 0.0093 - mean_absolute_error: 0.0430 - mean_squared_error: 0.0062 - val_loss: 0.0113 - val_mean_absolute_error: 0.0564 - val_mean_squared_error: 0.0083\n",
      "Epoch 22/50\n",
      "1324/1324 [==============================] - 0s 282us/sample - loss: 0.0091 - mean_absolute_error: 0.0426 - mean_squared_error: 0.0061 - val_loss: 0.0109 - val_mean_absolute_error: 0.0550 - val_mean_squared_error: 0.0079\n",
      "Epoch 23/50\n",
      "1324/1324 [==============================] - 0s 295us/sample - loss: 0.0089 - mean_absolute_error: 0.0421 - mean_squared_error: 0.0060 - val_loss: 0.0124 - val_mean_absolute_error: 0.0624 - val_mean_squared_error: 0.0096\n",
      "Epoch 24/50\n",
      "1324/1324 [==============================] - 0s 271us/sample - loss: 0.0086 - mean_absolute_error: 0.0417 - mean_squared_error: 0.0058 - val_loss: 0.0103 - val_mean_absolute_error: 0.0541 - val_mean_squared_error: 0.0075\n",
      "Epoch 25/50\n",
      "1324/1324 [==============================] - 0s 277us/sample - loss: 0.0082 - mean_absolute_error: 0.0409 - mean_squared_error: 0.0055 - val_loss: 0.0105 - val_mean_absolute_error: 0.0552 - val_mean_squared_error: 0.0078\n",
      "Epoch 26/50\n",
      "1324/1324 [==============================] - 0s 290us/sample - loss: 0.0081 - mean_absolute_error: 0.0408 - mean_squared_error: 0.0055 - val_loss: 0.0109 - val_mean_absolute_error: 0.0576 - val_mean_squared_error: 0.0083\n",
      "Epoch 27/50\n",
      "1324/1324 [==============================] - 0s 278us/sample - loss: 0.0078 - mean_absolute_error: 0.0399 - mean_squared_error: 0.0053 - val_loss: 0.0097 - val_mean_absolute_error: 0.0532 - val_mean_squared_error: 0.0072\n",
      "Epoch 28/50\n",
      "1324/1324 [==============================] - 0s 284us/sample - loss: 0.0077 - mean_absolute_error: 0.0397 - mean_squared_error: 0.0052 - val_loss: 0.0099 - val_mean_absolute_error: 0.0538 - val_mean_squared_error: 0.0075\n",
      "Epoch 29/50\n",
      "1324/1324 [==============================] - 0s 375us/sample - loss: 0.0076 - mean_absolute_error: 0.0394 - mean_squared_error: 0.0052 - val_loss: 0.0100 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0076\n",
      "Epoch 30/50\n",
      "1324/1324 [==============================] - 0s 329us/sample - loss: 0.0075 - mean_absolute_error: 0.0392 - mean_squared_error: 0.0051 - val_loss: 0.0100 - val_mean_absolute_error: 0.0547 - val_mean_squared_error: 0.0076\n",
      "Epoch 31/50\n",
      "1324/1324 [==============================] - 0s 285us/sample - loss: 0.0074 - mean_absolute_error: 0.0388 - mean_squared_error: 0.0051 - val_loss: 0.0093 - val_mean_absolute_error: 0.0524 - val_mean_squared_error: 0.0070\n",
      "Epoch 32/50\n",
      "1324/1324 [==============================] - 0s 306us/sample - loss: 0.0073 - mean_absolute_error: 0.0388 - mean_squared_error: 0.0051 - val_loss: 0.0098 - val_mean_absolute_error: 0.0545 - val_mean_squared_error: 0.0076\n",
      "Epoch 33/50\n",
      "1324/1324 [==============================] - 0s 339us/sample - loss: 0.0072 - mean_absolute_error: 0.0386 - mean_squared_error: 0.0050 - val_loss: 0.0093 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0072\n",
      "Epoch 34/50\n",
      "1324/1324 [==============================] - 1s 502us/sample - loss: 0.0071 - mean_absolute_error: 0.0385 - mean_squared_error: 0.0050 - val_loss: 0.0100 - val_mean_absolute_error: 0.0556 - val_mean_squared_error: 0.0079\n",
      "Epoch 35/50\n",
      "1324/1324 [==============================] - 0s 270us/sample - loss: 0.0070 - mean_absolute_error: 0.0379 - mean_squared_error: 0.0049 - val_loss: 0.0098 - val_mean_absolute_error: 0.0553 - val_mean_squared_error: 0.0078\n",
      "Epoch 36/50\n",
      "1324/1324 [==============================] - 0s 276us/sample - loss: 0.0069 - mean_absolute_error: 0.0377 - mean_squared_error: 0.0049 - val_loss: 0.0088 - val_mean_absolute_error: 0.0510 - val_mean_squared_error: 0.0069\n",
      "Epoch 37/50\n",
      "1324/1324 [==============================] - 0s 281us/sample - loss: 0.0068 - mean_absolute_error: 0.0378 - mean_squared_error: 0.0049 - val_loss: 0.0098 - val_mean_absolute_error: 0.0562 - val_mean_squared_error: 0.0079\n",
      "Epoch 38/50\n",
      "1324/1324 [==============================] - 0s 281us/sample - loss: 0.0068 - mean_absolute_error: 0.0376 - mean_squared_error: 0.0049 - val_loss: 0.0087 - val_mean_absolute_error: 0.0512 - val_mean_squared_error: 0.0068\n",
      "Epoch 39/50\n",
      "1324/1324 [==============================] - 0s 276us/sample - loss: 0.0067 - mean_absolute_error: 0.0375 - mean_squared_error: 0.0048 - val_loss: 0.0086 - val_mean_absolute_error: 0.0509 - val_mean_squared_error: 0.0068\n",
      "Epoch 40/50\n",
      "1324/1324 [==============================] - 0s 269us/sample - loss: 0.0066 - mean_absolute_error: 0.0373 - mean_squared_error: 0.0048 - val_loss: 0.0086 - val_mean_absolute_error: 0.0510 - val_mean_squared_error: 0.0068\n",
      "Epoch 41/50\n",
      "1324/1324 [==============================] - 0s 270us/sample - loss: 0.0065 - mean_absolute_error: 0.0370 - mean_squared_error: 0.0048 - val_loss: 0.0091 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0073\n",
      "Epoch 42/50\n",
      "1324/1324 [==============================] - 0s 259us/sample - loss: 0.0065 - mean_absolute_error: 0.0373 - mean_squared_error: 0.0048 - val_loss: 0.0085 - val_mean_absolute_error: 0.0507 - val_mean_squared_error: 0.0068\n",
      "Epoch 43/50\n",
      "1324/1324 [==============================] - 0s 269us/sample - loss: 0.0064 - mean_absolute_error: 0.0367 - mean_squared_error: 0.0047 - val_loss: 0.0089 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0073\n",
      "Epoch 44/50\n",
      "1324/1324 [==============================] - 0s 298us/sample - loss: 0.0063 - mean_absolute_error: 0.0365 - mean_squared_error: 0.0047 - val_loss: 0.0091 - val_mean_absolute_error: 0.0540 - val_mean_squared_error: 0.0075\n",
      "Epoch 45/50\n",
      "1324/1324 [==============================] - 0s 297us/sample - loss: 0.0062 - mean_absolute_error: 0.0363 - mean_squared_error: 0.0046 - val_loss: 0.0083 - val_mean_absolute_error: 0.0507 - val_mean_squared_error: 0.0067\n",
      "Epoch 46/50\n",
      "1324/1324 [==============================] - 0s 276us/sample - loss: 0.0062 - mean_absolute_error: 0.0367 - mean_squared_error: 0.0047 - val_loss: 0.0086 - val_mean_absolute_error: 0.0516 - val_mean_squared_error: 0.0070\n",
      "Epoch 47/50\n",
      "1324/1324 [==============================] - 0s 277us/sample - loss: 0.0061 - mean_absolute_error: 0.0362 - mean_squared_error: 0.0046 - val_loss: 0.0082 - val_mean_absolute_error: 0.0510 - val_mean_squared_error: 0.0067\n",
      "Epoch 48/50\n",
      "1324/1324 [==============================] - 0s 271us/sample - loss: 0.0061 - mean_absolute_error: 0.0361 - mean_squared_error: 0.0046 - val_loss: 0.0093 - val_mean_absolute_error: 0.0554 - val_mean_squared_error: 0.0078\n",
      "Epoch 49/50\n",
      "1324/1324 [==============================] - 0s 291us/sample - loss: 0.0061 - mean_absolute_error: 0.0363 - mean_squared_error: 0.0046 - val_loss: 0.0086 - val_mean_absolute_error: 0.0524 - val_mean_squared_error: 0.0072\n",
      "Epoch 50/50\n",
      "1324/1324 [==============================] - 0s 281us/sample - loss: 0.0060 - mean_absolute_error: 0.0360 - mean_squared_error: 0.0046 - val_loss: 0.0092 - val_mean_absolute_error: 0.0554 - val_mean_squared_error: 0.0078\n",
      "Train on 1324 samples, validate on 332 samples\n",
      "Epoch 1/50\n",
      "1324/1324 [==============================] - 1s 930us/sample - loss: 0.0516 - mean_absolute_error: 0.1392 - mean_squared_error: 0.0433 - val_loss: 0.0593 - val_mean_absolute_error: 0.1597 - val_mean_squared_error: 0.0511\n",
      "Epoch 2/50\n",
      "1324/1324 [==============================] - 0s 147us/sample - loss: 0.0425 - mean_absolute_error: 0.1275 - mean_squared_error: 0.0344 - val_loss: 0.0573 - val_mean_absolute_error: 0.1568 - val_mean_squared_error: 0.0493\n",
      "Epoch 3/50\n",
      "1324/1324 [==============================] - 0s 145us/sample - loss: 0.0379 - mean_absolute_error: 0.1211 - mean_squared_error: 0.0300 - val_loss: 0.0564 - val_mean_absolute_error: 0.1559 - val_mean_squared_error: 0.0487\n",
      "Epoch 4/50\n",
      "1324/1324 [==============================] - 0s 127us/sample - loss: 0.0345 - mean_absolute_error: 0.1157 - mean_squared_error: 0.0268 - val_loss: 0.0556 - val_mean_absolute_error: 0.1552 - val_mean_squared_error: 0.0481\n",
      "Epoch 5/50\n",
      "1324/1324 [==============================] - 0s 135us/sample - loss: 0.0316 - mean_absolute_error: 0.1098 - mean_squared_error: 0.0242 - val_loss: 0.0548 - val_mean_absolute_error: 0.1543 - val_mean_squared_error: 0.0476\n",
      "Epoch 6/50\n",
      "1324/1324 [==============================] - 0s 142us/sample - loss: 0.0292 - mean_absolute_error: 0.1032 - mean_squared_error: 0.0220 - val_loss: 0.0538 - val_mean_absolute_error: 0.1531 - val_mean_squared_error: 0.0468\n",
      "Epoch 7/50\n",
      "1324/1324 [==============================] - 0s 138us/sample - loss: 0.0270 - mean_absolute_error: 0.0969 - mean_squared_error: 0.0201 - val_loss: 0.0535 - val_mean_absolute_error: 0.1528 - val_mean_squared_error: 0.0467\n",
      "Epoch 8/50\n",
      "1324/1324 [==============================] - 0s 145us/sample - loss: 0.0251 - mean_absolute_error: 0.0909 - mean_squared_error: 0.0184 - val_loss: 0.0515 - val_mean_absolute_error: 0.1500 - val_mean_squared_error: 0.0449\n",
      "Epoch 9/50\n",
      "1324/1324 [==============================] - 0s 174us/sample - loss: 0.0232 - mean_absolute_error: 0.0853 - mean_squared_error: 0.0167 - val_loss: 0.0496 - val_mean_absolute_error: 0.1470 - val_mean_squared_error: 0.0432\n",
      "Epoch 10/50\n",
      "1324/1324 [==============================] - 0s 165us/sample - loss: 0.0215 - mean_absolute_error: 0.0801 - mean_squared_error: 0.0151 - val_loss: 0.0475 - val_mean_absolute_error: 0.1437 - val_mean_squared_error: 0.0412\n",
      "Epoch 11/50\n",
      "1324/1324 [==============================] - 0s 154us/sample - loss: 0.0199 - mean_absolute_error: 0.0753 - mean_squared_error: 0.0138 - val_loss: 0.0451 - val_mean_absolute_error: 0.1397 - val_mean_squared_error: 0.0390\n",
      "Epoch 12/50\n",
      "1324/1324 [==============================] - 0s 139us/sample - loss: 0.0185 - mean_absolute_error: 0.0707 - mean_squared_error: 0.0125 - val_loss: 0.0402 - val_mean_absolute_error: 0.1308 - val_mean_squared_error: 0.0343\n",
      "Epoch 13/50\n",
      "1324/1324 [==============================] - 0s 140us/sample - loss: 0.0173 - mean_absolute_error: 0.0670 - mean_squared_error: 0.0115 - val_loss: 0.0381 - val_mean_absolute_error: 0.1267 - val_mean_squared_error: 0.0323\n",
      "Epoch 14/50\n",
      "1324/1324 [==============================] - 0s 146us/sample - loss: 0.0163 - mean_absolute_error: 0.0634 - mean_squared_error: 0.0106 - val_loss: 0.0345 - val_mean_absolute_error: 0.1195 - val_mean_squared_error: 0.0288\n",
      "Epoch 15/50\n",
      "1324/1324 [==============================] - 0s 150us/sample - loss: 0.0154 - mean_absolute_error: 0.0604 - mean_squared_error: 0.0099 - val_loss: 0.0317 - val_mean_absolute_error: 0.1137 - val_mean_squared_error: 0.0263\n",
      "Epoch 16/50\n",
      "1324/1324 [==============================] - 0s 146us/sample - loss: 0.0146 - mean_absolute_error: 0.0577 - mean_squared_error: 0.0092 - val_loss: 0.0278 - val_mean_absolute_error: 0.1046 - val_mean_squared_error: 0.0225\n",
      "Epoch 17/50\n",
      "1324/1324 [==============================] - 0s 133us/sample - loss: 0.0140 - mean_absolute_error: 0.0557 - mean_squared_error: 0.0087 - val_loss: 0.0265 - val_mean_absolute_error: 0.1015 - val_mean_squared_error: 0.0213\n",
      "Epoch 18/50\n",
      "1324/1324 [==============================] - 0s 141us/sample - loss: 0.0135 - mean_absolute_error: 0.0537 - mean_squared_error: 0.0083 - val_loss: 0.0218 - val_mean_absolute_error: 0.0886 - val_mean_squared_error: 0.0167\n",
      "Epoch 19/50\n",
      "1324/1324 [==============================] - 0s 145us/sample - loss: 0.0129 - mean_absolute_error: 0.0519 - mean_squared_error: 0.0079 - val_loss: 0.0214 - val_mean_absolute_error: 0.0875 - val_mean_squared_error: 0.0164\n",
      "Epoch 20/50\n",
      "1324/1324 [==============================] - 0s 154us/sample - loss: 0.0125 - mean_absolute_error: 0.0506 - mean_squared_error: 0.0076 - val_loss: 0.0200 - val_mean_absolute_error: 0.0834 - val_mean_squared_error: 0.0151\n",
      "Epoch 21/50\n",
      "1324/1324 [==============================] - 0s 154us/sample - loss: 0.0122 - mean_absolute_error: 0.0496 - mean_squared_error: 0.0074 - val_loss: 0.0175 - val_mean_absolute_error: 0.0751 - val_mean_squared_error: 0.0128\n",
      "Epoch 22/50\n",
      "1324/1324 [==============================] - 0s 153us/sample - loss: 0.0119 - mean_absolute_error: 0.0486 - mean_squared_error: 0.0072 - val_loss: 0.0167 - val_mean_absolute_error: 0.0721 - val_mean_squared_error: 0.0120\n",
      "Epoch 23/50\n",
      "1324/1324 [==============================] - 0s 149us/sample - loss: 0.0117 - mean_absolute_error: 0.0479 - mean_squared_error: 0.0071 - val_loss: 0.0164 - val_mean_absolute_error: 0.0715 - val_mean_squared_error: 0.0119\n",
      "Epoch 24/50\n",
      "1324/1324 [==============================] - 0s 157us/sample - loss: 0.0115 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0069 - val_loss: 0.0158 - val_mean_absolute_error: 0.0693 - val_mean_squared_error: 0.0113\n",
      "Epoch 25/50\n",
      "1324/1324 [==============================] - 0s 145us/sample - loss: 0.0113 - mean_absolute_error: 0.0467 - mean_squared_error: 0.0069 - val_loss: 0.0153 - val_mean_absolute_error: 0.0675 - val_mean_squared_error: 0.0109\n",
      "Epoch 26/50\n",
      "1324/1324 [==============================] - 0s 127us/sample - loss: 0.0112 - mean_absolute_error: 0.0464 - mean_squared_error: 0.0068 - val_loss: 0.0157 - val_mean_absolute_error: 0.0694 - val_mean_squared_error: 0.0114\n",
      "Epoch 27/50\n",
      "1324/1324 [==============================] - 0s 138us/sample - loss: 0.0109 - mean_absolute_error: 0.0458 - mean_squared_error: 0.0067 - val_loss: 0.0150 - val_mean_absolute_error: 0.0670 - val_mean_squared_error: 0.0108\n",
      "Epoch 28/50\n",
      "1324/1324 [==============================] - 0s 144us/sample - loss: 0.0107 - mean_absolute_error: 0.0449 - mean_squared_error: 0.0065 - val_loss: 0.0146 - val_mean_absolute_error: 0.0659 - val_mean_squared_error: 0.0105\n",
      "Epoch 29/50\n",
      "1324/1324 [==============================] - 0s 133us/sample - loss: 0.0106 - mean_absolute_error: 0.0449 - mean_squared_error: 0.0065 - val_loss: 0.0128 - val_mean_absolute_error: 0.0585 - val_mean_squared_error: 0.0088\n",
      "Epoch 30/50\n",
      "1324/1324 [==============================] - 0s 137us/sample - loss: 0.0104 - mean_absolute_error: 0.0442 - mean_squared_error: 0.0064 - val_loss: 0.0128 - val_mean_absolute_error: 0.0591 - val_mean_squared_error: 0.0088\n",
      "Epoch 31/50\n",
      "1324/1324 [==============================] - 0s 141us/sample - loss: 0.0102 - mean_absolute_error: 0.0438 - mean_squared_error: 0.0062 - val_loss: 0.0131 - val_mean_absolute_error: 0.0610 - val_mean_squared_error: 0.0092\n",
      "Epoch 32/50\n",
      "1324/1324 [==============================] - 0s 130us/sample - loss: 0.0099 - mean_absolute_error: 0.0431 - mean_squared_error: 0.0060 - val_loss: 0.0121 - val_mean_absolute_error: 0.0567 - val_mean_squared_error: 0.0082\n",
      "Epoch 33/50\n",
      "1324/1324 [==============================] - 0s 134us/sample - loss: 0.0097 - mean_absolute_error: 0.0426 - mean_squared_error: 0.0059 - val_loss: 0.0119 - val_mean_absolute_error: 0.0563 - val_mean_squared_error: 0.0081\n",
      "Epoch 34/50\n",
      "1324/1324 [==============================] - 0s 132us/sample - loss: 0.0096 - mean_absolute_error: 0.0422 - mean_squared_error: 0.0059 - val_loss: 0.0124 - val_mean_absolute_error: 0.0589 - val_mean_squared_error: 0.0087\n",
      "Epoch 35/50\n",
      "1324/1324 [==============================] - 0s 146us/sample - loss: 0.0095 - mean_absolute_error: 0.0420 - mean_squared_error: 0.0058 - val_loss: 0.0118 - val_mean_absolute_error: 0.0563 - val_mean_squared_error: 0.0082\n",
      "Epoch 36/50\n",
      "1324/1324 [==============================] - 0s 150us/sample - loss: 0.0093 - mean_absolute_error: 0.0415 - mean_squared_error: 0.0057 - val_loss: 0.0117 - val_mean_absolute_error: 0.0562 - val_mean_squared_error: 0.0081\n",
      "Epoch 37/50\n",
      "1324/1324 [==============================] - 0s 146us/sample - loss: 0.0092 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0057 - val_loss: 0.0114 - val_mean_absolute_error: 0.0551 - val_mean_squared_error: 0.0079\n",
      "Epoch 38/50\n",
      "1324/1324 [==============================] - 0s 135us/sample - loss: 0.0091 - mean_absolute_error: 0.0411 - mean_squared_error: 0.0056 - val_loss: 0.0113 - val_mean_absolute_error: 0.0549 - val_mean_squared_error: 0.0078\n",
      "Epoch 39/50\n",
      "1324/1324 [==============================] - 0s 130us/sample - loss: 0.0090 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0056 - val_loss: 0.0109 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0075\n",
      "Epoch 40/50\n",
      "1324/1324 [==============================] - 0s 170us/sample - loss: 0.0089 - mean_absolute_error: 0.0406 - mean_squared_error: 0.0055 - val_loss: 0.0111 - val_mean_absolute_error: 0.0546 - val_mean_squared_error: 0.0078\n",
      "Epoch 41/50\n",
      "1324/1324 [==============================] - 0s 145us/sample - loss: 0.0087 - mean_absolute_error: 0.0403 - mean_squared_error: 0.0055 - val_loss: 0.0111 - val_mean_absolute_error: 0.0552 - val_mean_squared_error: 0.0079\n",
      "Epoch 42/50\n",
      "1324/1324 [==============================] - 0s 147us/sample - loss: 0.0087 - mean_absolute_error: 0.0406 - mean_squared_error: 0.0055 - val_loss: 0.0108 - val_mean_absolute_error: 0.0534 - val_mean_squared_error: 0.0076\n",
      "Epoch 43/50\n",
      "1324/1324 [==============================] - 0s 160us/sample - loss: 0.0086 - mean_absolute_error: 0.0398 - mean_squared_error: 0.0054 - val_loss: 0.0114 - val_mean_absolute_error: 0.0565 - val_mean_squared_error: 0.0082\n",
      "Epoch 44/50\n",
      "1324/1324 [==============================] - 0s 147us/sample - loss: 0.0085 - mean_absolute_error: 0.0396 - mean_squared_error: 0.0054 - val_loss: 0.0106 - val_mean_absolute_error: 0.0531 - val_mean_squared_error: 0.0075\n",
      "Epoch 45/50\n",
      "1324/1324 [==============================] - 0s 146us/sample - loss: 0.0084 - mean_absolute_error: 0.0393 - mean_squared_error: 0.0053 - val_loss: 0.0107 - val_mean_absolute_error: 0.0539 - val_mean_squared_error: 0.0077\n",
      "Epoch 46/50\n",
      "1324/1324 [==============================] - 0s 146us/sample - loss: 0.0083 - mean_absolute_error: 0.0395 - mean_squared_error: 0.0053 - val_loss: 0.0103 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0073\n",
      "Epoch 47/50\n",
      "1324/1324 [==============================] - 0s 137us/sample - loss: 0.0082 - mean_absolute_error: 0.0392 - mean_squared_error: 0.0053 - val_loss: 0.0102 - val_mean_absolute_error: 0.0522 - val_mean_squared_error: 0.0073\n",
      "Epoch 48/50\n",
      "1324/1324 [==============================] - 0s 127us/sample - loss: 0.0082 - mean_absolute_error: 0.0391 - mean_squared_error: 0.0053 - val_loss: 0.0104 - val_mean_absolute_error: 0.0533 - val_mean_squared_error: 0.0075\n",
      "Epoch 49/50\n",
      "1324/1324 [==============================] - 0s 141us/sample - loss: 0.0081 - mean_absolute_error: 0.0388 - mean_squared_error: 0.0052 - val_loss: 0.0103 - val_mean_absolute_error: 0.0528 - val_mean_squared_error: 0.0074\n",
      "Epoch 50/50\n",
      "1324/1324 [==============================] - 0s 133us/sample - loss: 0.0080 - mean_absolute_error: 0.0384 - mean_squared_error: 0.0052 - val_loss: 0.0102 - val_mean_absolute_error: 0.0529 - val_mean_squared_error: 0.0075\n",
      "Train on 1324 samples, validate on 332 samples\n",
      "Epoch 1/50\n",
      "1324/1324 [==============================] - 1s 1ms/sample - loss: 0.0618 - mean_absolute_error: 0.1560 - mean_squared_error: 0.0534 - val_loss: 0.0618 - val_mean_absolute_error: 0.1632 - val_mean_squared_error: 0.0535\n",
      "Epoch 2/50\n",
      "1324/1324 [==============================] - 0s 106us/sample - loss: 0.0475 - mean_absolute_error: 0.1332 - mean_squared_error: 0.0393 - val_loss: 0.0593 - val_mean_absolute_error: 0.1596 - val_mean_squared_error: 0.0512\n",
      "Epoch 3/50\n",
      "1324/1324 [==============================] - 0s 89us/sample - loss: 0.0427 - mean_absolute_error: 0.1289 - mean_squared_error: 0.0347 - val_loss: 0.0564 - val_mean_absolute_error: 0.1558 - val_mean_squared_error: 0.0484\n",
      "Epoch 4/50\n",
      "1324/1324 [==============================] - 0s 105us/sample - loss: 0.0384 - mean_absolute_error: 0.1241 - mean_squared_error: 0.0306 - val_loss: 0.0545 - val_mean_absolute_error: 0.1538 - val_mean_squared_error: 0.0468\n",
      "Epoch 5/50\n",
      "1324/1324 [==============================] - 0s 169us/sample - loss: 0.0355 - mean_absolute_error: 0.1186 - mean_squared_error: 0.0278 - val_loss: 0.0533 - val_mean_absolute_error: 0.1525 - val_mean_squared_error: 0.0457\n",
      "Epoch 6/50\n",
      "1324/1324 [==============================] - 0s 127us/sample - loss: 0.0333 - mean_absolute_error: 0.1143 - mean_squared_error: 0.0258 - val_loss: 0.0521 - val_mean_absolute_error: 0.1516 - val_mean_squared_error: 0.0448\n",
      "Epoch 7/50\n",
      "1324/1324 [==============================] - 0s 112us/sample - loss: 0.0315 - mean_absolute_error: 0.1100 - mean_squared_error: 0.0242 - val_loss: 0.0511 - val_mean_absolute_error: 0.1506 - val_mean_squared_error: 0.0440\n",
      "Epoch 8/50\n",
      "1324/1324 [==============================] - 0s 126us/sample - loss: 0.0298 - mean_absolute_error: 0.1053 - mean_squared_error: 0.0227 - val_loss: 0.0504 - val_mean_absolute_error: 0.1497 - val_mean_squared_error: 0.0434\n",
      "Epoch 9/50\n",
      "1324/1324 [==============================] - 0s 105us/sample - loss: 0.0282 - mean_absolute_error: 0.1011 - mean_squared_error: 0.0213 - val_loss: 0.0495 - val_mean_absolute_error: 0.1487 - val_mean_squared_error: 0.0427\n",
      "Epoch 10/50\n",
      "1324/1324 [==============================] - 0s 97us/sample - loss: 0.0264 - mean_absolute_error: 0.0963 - mean_squared_error: 0.0197 - val_loss: 0.0481 - val_mean_absolute_error: 0.1466 - val_mean_squared_error: 0.0414\n",
      "Epoch 11/50\n",
      "1324/1324 [==============================] - 0s 135us/sample - loss: 0.0246 - mean_absolute_error: 0.0923 - mean_squared_error: 0.0181 - val_loss: 0.0474 - val_mean_absolute_error: 0.1457 - val_mean_squared_error: 0.0409\n",
      "Epoch 12/50\n",
      "1324/1324 [==============================] - 0s 109us/sample - loss: 0.0230 - mean_absolute_error: 0.0875 - mean_squared_error: 0.0166 - val_loss: 0.0461 - val_mean_absolute_error: 0.1437 - val_mean_squared_error: 0.0398\n",
      "Epoch 13/50\n",
      "1324/1324 [==============================] - 0s 144us/sample - loss: 0.0216 - mean_absolute_error: 0.0835 - mean_squared_error: 0.0154 - val_loss: 0.0450 - val_mean_absolute_error: 0.1419 - val_mean_squared_error: 0.0388\n",
      "Epoch 14/50\n",
      "1324/1324 [==============================] - 0s 108us/sample - loss: 0.0203 - mean_absolute_error: 0.0791 - mean_squared_error: 0.0142 - val_loss: 0.0436 - val_mean_absolute_error: 0.1399 - val_mean_squared_error: 0.0376\n",
      "Epoch 15/50\n",
      "1324/1324 [==============================] - 0s 121us/sample - loss: 0.0191 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0131 - val_loss: 0.0428 - val_mean_absolute_error: 0.1387 - val_mean_squared_error: 0.0369\n",
      "Epoch 16/50\n",
      "1324/1324 [==============================] - 0s 141us/sample - loss: 0.0181 - mean_absolute_error: 0.0724 - mean_squared_error: 0.0122 - val_loss: 0.0417 - val_mean_absolute_error: 0.1364 - val_mean_squared_error: 0.0359\n",
      "Epoch 17/50\n",
      "1324/1324 [==============================] - 0s 111us/sample - loss: 0.0171 - mean_absolute_error: 0.0691 - mean_squared_error: 0.0114 - val_loss: 0.0400 - val_mean_absolute_error: 0.1331 - val_mean_squared_error: 0.0344\n",
      "Epoch 18/50\n",
      "1324/1324 [==============================] - 0s 99us/sample - loss: 0.0164 - mean_absolute_error: 0.0665 - mean_squared_error: 0.0108 - val_loss: 0.0377 - val_mean_absolute_error: 0.1287 - val_mean_squared_error: 0.0322\n",
      "Epoch 19/50\n",
      "1324/1324 [==============================] - 0s 106us/sample - loss: 0.0156 - mean_absolute_error: 0.0639 - mean_squared_error: 0.0102 - val_loss: 0.0364 - val_mean_absolute_error: 0.1258 - val_mean_squared_error: 0.0310\n",
      "Epoch 20/50\n",
      "1324/1324 [==============================] - 0s 122us/sample - loss: 0.0150 - mean_absolute_error: 0.0617 - mean_squared_error: 0.0096 - val_loss: 0.0352 - val_mean_absolute_error: 0.1231 - val_mean_squared_error: 0.0299\n",
      "Epoch 21/50\n",
      "1324/1324 [==============================] - 0s 121us/sample - loss: 0.0144 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0092 - val_loss: 0.0332 - val_mean_absolute_error: 0.1188 - val_mean_squared_error: 0.0281\n",
      "Epoch 22/50\n",
      "1324/1324 [==============================] - 0s 135us/sample - loss: 0.0139 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0088 - val_loss: 0.0319 - val_mean_absolute_error: 0.1157 - val_mean_squared_error: 0.0268\n",
      "Epoch 23/50\n",
      "1324/1324 [==============================] - 0s 134us/sample - loss: 0.0134 - mean_absolute_error: 0.0559 - mean_squared_error: 0.0083 - val_loss: 0.0291 - val_mean_absolute_error: 0.1096 - val_mean_squared_error: 0.0241\n",
      "Epoch 24/50\n",
      "1324/1324 [==============================] - 0s 128us/sample - loss: 0.0130 - mean_absolute_error: 0.0545 - mean_squared_error: 0.0080 - val_loss: 0.0280 - val_mean_absolute_error: 0.1068 - val_mean_squared_error: 0.0231\n",
      "Epoch 25/50\n",
      "1324/1324 [==============================] - 0s 126us/sample - loss: 0.0126 - mean_absolute_error: 0.0533 - mean_squared_error: 0.0078 - val_loss: 0.0263 - val_mean_absolute_error: 0.1028 - val_mean_squared_error: 0.0215\n",
      "Epoch 26/50\n",
      "1324/1324 [==============================] - 0s 124us/sample - loss: 0.0123 - mean_absolute_error: 0.0524 - mean_squared_error: 0.0076 - val_loss: 0.0246 - val_mean_absolute_error: 0.0984 - val_mean_squared_error: 0.0199\n",
      "Epoch 27/50\n",
      "1324/1324 [==============================] - 0s 126us/sample - loss: 0.0120 - mean_absolute_error: 0.0512 - mean_squared_error: 0.0074 - val_loss: 0.0221 - val_mean_absolute_error: 0.0919 - val_mean_squared_error: 0.0174\n",
      "Epoch 28/50\n",
      "1324/1324 [==============================] - 0s 124us/sample - loss: 0.0118 - mean_absolute_error: 0.0503 - mean_squared_error: 0.0072 - val_loss: 0.0220 - val_mean_absolute_error: 0.0918 - val_mean_squared_error: 0.0175\n",
      "Epoch 29/50\n",
      "1324/1324 [==============================] - 0s 122us/sample - loss: 0.0115 - mean_absolute_error: 0.0492 - mean_squared_error: 0.0070 - val_loss: 0.0205 - val_mean_absolute_error: 0.0878 - val_mean_squared_error: 0.0160\n",
      "Epoch 30/50\n",
      "1324/1324 [==============================] - 0s 124us/sample - loss: 0.0113 - mean_absolute_error: 0.0488 - mean_squared_error: 0.0069 - val_loss: 0.0194 - val_mean_absolute_error: 0.0842 - val_mean_squared_error: 0.0150\n",
      "Epoch 31/50\n",
      "1324/1324 [==============================] - 0s 117us/sample - loss: 0.0111 - mean_absolute_error: 0.0480 - mean_squared_error: 0.0067 - val_loss: 0.0187 - val_mean_absolute_error: 0.0820 - val_mean_squared_error: 0.0144\n",
      "Epoch 32/50\n",
      "1324/1324 [==============================] - 0s 123us/sample - loss: 0.0109 - mean_absolute_error: 0.0474 - mean_squared_error: 0.0066 - val_loss: 0.0178 - val_mean_absolute_error: 0.0793 - val_mean_squared_error: 0.0136\n",
      "Epoch 33/50\n",
      "1324/1324 [==============================] - 0s 135us/sample - loss: 0.0108 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0066 - val_loss: 0.0160 - val_mean_absolute_error: 0.0735 - val_mean_squared_error: 0.0118\n",
      "Epoch 34/50\n",
      "1324/1324 [==============================] - 0s 125us/sample - loss: 0.0106 - mean_absolute_error: 0.0462 - mean_squared_error: 0.0064 - val_loss: 0.0160 - val_mean_absolute_error: 0.0734 - val_mean_squared_error: 0.0118\n",
      "Epoch 35/50\n",
      "1324/1324 [==============================] - 0s 121us/sample - loss: 0.0105 - mean_absolute_error: 0.0461 - mean_squared_error: 0.0064 - val_loss: 0.0157 - val_mean_absolute_error: 0.0726 - val_mean_squared_error: 0.0116\n",
      "Epoch 36/50\n",
      "1324/1324 [==============================] - 0s 110us/sample - loss: 0.0104 - mean_absolute_error: 0.0459 - mean_squared_error: 0.0064 - val_loss: 0.0157 - val_mean_absolute_error: 0.0731 - val_mean_squared_error: 0.0117\n",
      "Epoch 37/50\n",
      "1324/1324 [==============================] - 0s 108us/sample - loss: 0.0103 - mean_absolute_error: 0.0456 - mean_squared_error: 0.0063 - val_loss: 0.0143 - val_mean_absolute_error: 0.0680 - val_mean_squared_error: 0.0104\n",
      "Epoch 38/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0100 - mean_absolute_error: 0.0446 - mean_squared_error: 0.0061 - val_loss: 0.0139 - val_mean_absolute_error: 0.0665 - val_mean_squared_error: 0.0100\n",
      "Epoch 39/50\n",
      "1324/1324 [==============================] - 0s 108us/sample - loss: 0.0099 - mean_absolute_error: 0.0443 - mean_squared_error: 0.0061 - val_loss: 0.0140 - val_mean_absolute_error: 0.0671 - val_mean_squared_error: 0.0102\n",
      "Epoch 40/50\n",
      "1324/1324 [==============================] - 0s 103us/sample - loss: 0.0098 - mean_absolute_error: 0.0441 - mean_squared_error: 0.0061 - val_loss: 0.0133 - val_mean_absolute_error: 0.0645 - val_mean_squared_error: 0.0096\n",
      "Epoch 41/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0097 - mean_absolute_error: 0.0438 - mean_squared_error: 0.0060 - val_loss: 0.0128 - val_mean_absolute_error: 0.0629 - val_mean_squared_error: 0.0092\n",
      "Epoch 42/50\n",
      "1324/1324 [==============================] - 0s 95us/sample - loss: 0.0096 - mean_absolute_error: 0.0433 - mean_squared_error: 0.0059 - val_loss: 0.0127 - val_mean_absolute_error: 0.0623 - val_mean_squared_error: 0.0091\n",
      "Epoch 43/50\n",
      "1324/1324 [==============================] - 0s 96us/sample - loss: 0.0096 - mean_absolute_error: 0.0436 - mean_squared_error: 0.0060 - val_loss: 0.0134 - val_mean_absolute_error: 0.0652 - val_mean_squared_error: 0.0098\n",
      "Epoch 44/50\n",
      "1324/1324 [==============================] - 0s 108us/sample - loss: 0.0094 - mean_absolute_error: 0.0431 - mean_squared_error: 0.0059 - val_loss: 0.0123 - val_mean_absolute_error: 0.0612 - val_mean_squared_error: 0.0088\n",
      "Epoch 45/50\n",
      "1324/1324 [==============================] - 0s 101us/sample - loss: 0.0094 - mean_absolute_error: 0.0430 - mean_squared_error: 0.0059 - val_loss: 0.0126 - val_mean_absolute_error: 0.0624 - val_mean_squared_error: 0.0091\n",
      "Epoch 46/50\n",
      "1324/1324 [==============================] - 0s 98us/sample - loss: 0.0093 - mean_absolute_error: 0.0428 - mean_squared_error: 0.0058 - val_loss: 0.0115 - val_mean_absolute_error: 0.0580 - val_mean_squared_error: 0.0081\n",
      "Epoch 47/50\n",
      "1324/1324 [==============================] - 0s 111us/sample - loss: 0.0092 - mean_absolute_error: 0.0425 - mean_squared_error: 0.0058 - val_loss: 0.0124 - val_mean_absolute_error: 0.0620 - val_mean_squared_error: 0.0090\n",
      "Epoch 48/50\n",
      "1324/1324 [==============================] - 0s 102us/sample - loss: 0.0091 - mean_absolute_error: 0.0423 - mean_squared_error: 0.0057 - val_loss: 0.0118 - val_mean_absolute_error: 0.0595 - val_mean_squared_error: 0.0084\n",
      "Epoch 49/50\n",
      "1324/1324 [==============================] - 0s 98us/sample - loss: 0.0090 - mean_absolute_error: 0.0420 - mean_squared_error: 0.0057 - val_loss: 0.0116 - val_mean_absolute_error: 0.0590 - val_mean_squared_error: 0.0083\n",
      "Epoch 50/50\n",
      "1324/1324 [==============================] - 0s 103us/sample - loss: 0.0089 - mean_absolute_error: 0.0418 - mean_squared_error: 0.0057 - val_loss: 0.0117 - val_mean_absolute_error: 0.0595 - val_mean_squared_error: 0.0085\n",
      "Train on 1324 samples, validate on 332 samples\n",
      "Epoch 1/50\n",
      "1324/1324 [==============================] - 1s 1ms/sample - loss: 0.0609 - mean_absolute_error: 0.1565 - mean_squared_error: 0.0526 - val_loss: 0.0611 - val_mean_absolute_error: 0.1623 - val_mean_squared_error: 0.0529\n",
      "Epoch 2/50\n",
      "1324/1324 [==============================] - 0s 103us/sample - loss: 0.0479 - mean_absolute_error: 0.1323 - mean_squared_error: 0.0397 - val_loss: 0.0582 - val_mean_absolute_error: 0.1580 - val_mean_squared_error: 0.0501\n",
      "Epoch 3/50\n",
      "1324/1324 [==============================] - 0s 80us/sample - loss: 0.0441 - mean_absolute_error: 0.1278 - mean_squared_error: 0.0360 - val_loss: 0.0549 - val_mean_absolute_error: 0.1533 - val_mean_squared_error: 0.0469\n",
      "Epoch 4/50\n",
      "1324/1324 [==============================] - 0s 89us/sample - loss: 0.0410 - mean_absolute_error: 0.1243 - mean_squared_error: 0.0330 - val_loss: 0.0516 - val_mean_absolute_error: 0.1488 - val_mean_squared_error: 0.0437\n",
      "Epoch 5/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0384 - mean_absolute_error: 0.1209 - mean_squared_error: 0.0306 - val_loss: 0.0495 - val_mean_absolute_error: 0.1461 - val_mean_squared_error: 0.0417\n",
      "Epoch 6/50\n",
      "1324/1324 [==============================] - 0s 90us/sample - loss: 0.0362 - mean_absolute_error: 0.1180 - mean_squared_error: 0.0285 - val_loss: 0.0474 - val_mean_absolute_error: 0.1435 - val_mean_squared_error: 0.0398\n",
      "Epoch 7/50\n",
      "1324/1324 [==============================] - 0s 107us/sample - loss: 0.0342 - mean_absolute_error: 0.1139 - mean_squared_error: 0.0267 - val_loss: 0.0455 - val_mean_absolute_error: 0.1405 - val_mean_squared_error: 0.0381\n",
      "Epoch 8/50\n",
      "1324/1324 [==============================] - 0s 99us/sample - loss: 0.0324 - mean_absolute_error: 0.1105 - mean_squared_error: 0.0250 - val_loss: 0.0439 - val_mean_absolute_error: 0.1381 - val_mean_squared_error: 0.0365\n",
      "Epoch 9/50\n",
      "1324/1324 [==============================] - 0s 90us/sample - loss: 0.0304 - mean_absolute_error: 0.1059 - mean_squared_error: 0.0231 - val_loss: 0.0432 - val_mean_absolute_error: 0.1371 - val_mean_squared_error: 0.0360\n",
      "Epoch 10/50\n",
      "1324/1324 [==============================] - 0s 104us/sample - loss: 0.0286 - mean_absolute_error: 0.1016 - mean_squared_error: 0.0215 - val_loss: 0.0418 - val_mean_absolute_error: 0.1346 - val_mean_squared_error: 0.0347\n",
      "Epoch 11/50\n",
      "1324/1324 [==============================] - 0s 102us/sample - loss: 0.0272 - mean_absolute_error: 0.0974 - mean_squared_error: 0.0202 - val_loss: 0.0410 - val_mean_absolute_error: 0.1333 - val_mean_squared_error: 0.0341\n",
      "Epoch 12/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0258 - mean_absolute_error: 0.0934 - mean_squared_error: 0.0189 - val_loss: 0.0400 - val_mean_absolute_error: 0.1314 - val_mean_squared_error: 0.0331\n",
      "Epoch 13/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0246 - mean_absolute_error: 0.0899 - mean_squared_error: 0.0178 - val_loss: 0.0388 - val_mean_absolute_error: 0.1291 - val_mean_squared_error: 0.0321\n",
      "Epoch 14/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0234 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0167 - val_loss: 0.0382 - val_mean_absolute_error: 0.1281 - val_mean_squared_error: 0.0316\n",
      "Epoch 15/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0224 - mean_absolute_error: 0.0834 - mean_squared_error: 0.0158 - val_loss: 0.0372 - val_mean_absolute_error: 0.1262 - val_mean_squared_error: 0.0307\n",
      "Epoch 16/50\n",
      "1324/1324 [==============================] - 0s 104us/sample - loss: 0.0214 - mean_absolute_error: 0.0803 - mean_squared_error: 0.0149 - val_loss: 0.0361 - val_mean_absolute_error: 0.1238 - val_mean_squared_error: 0.0297\n",
      "Epoch 17/50\n",
      "1324/1324 [==============================] - 0s 98us/sample - loss: 0.0204 - mean_absolute_error: 0.0775 - mean_squared_error: 0.0141 - val_loss: 0.0350 - val_mean_absolute_error: 0.1216 - val_mean_squared_error: 0.0287\n",
      "Epoch 18/50\n",
      "1324/1324 [==============================] - 0s 106us/sample - loss: 0.0194 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0132 - val_loss: 0.0331 - val_mean_absolute_error: 0.1177 - val_mean_squared_error: 0.0269\n",
      "Epoch 19/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0185 - mean_absolute_error: 0.0721 - mean_squared_error: 0.0124 - val_loss: 0.0324 - val_mean_absolute_error: 0.1159 - val_mean_squared_error: 0.0263\n",
      "Epoch 20/50\n",
      "1324/1324 [==============================] - 0s 90us/sample - loss: 0.0177 - mean_absolute_error: 0.0692 - mean_squared_error: 0.0116 - val_loss: 0.0314 - val_mean_absolute_error: 0.1135 - val_mean_squared_error: 0.0254\n",
      "Epoch 21/50\n",
      "1324/1324 [==============================] - 0s 92us/sample - loss: 0.0171 - mean_absolute_error: 0.0669 - mean_squared_error: 0.0111 - val_loss: 0.0298 - val_mean_absolute_error: 0.1100 - val_mean_squared_error: 0.0239\n",
      "Epoch 22/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0165 - mean_absolute_error: 0.0651 - mean_squared_error: 0.0106 - val_loss: 0.0288 - val_mean_absolute_error: 0.1071 - val_mean_squared_error: 0.0229\n",
      "Epoch 23/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0160 - mean_absolute_error: 0.0632 - mean_squared_error: 0.0102 - val_loss: 0.0274 - val_mean_absolute_error: 0.1040 - val_mean_squared_error: 0.0217\n",
      "Epoch 24/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0155 - mean_absolute_error: 0.0615 - mean_squared_error: 0.0098 - val_loss: 0.0263 - val_mean_absolute_error: 0.1010 - val_mean_squared_error: 0.0206\n",
      "Epoch 25/50\n",
      "1324/1324 [==============================] - 0s 96us/sample - loss: 0.0151 - mean_absolute_error: 0.0600 - mean_squared_error: 0.0095 - val_loss: 0.0256 - val_mean_absolute_error: 0.0991 - val_mean_squared_error: 0.0200\n",
      "Epoch 26/50\n",
      "1324/1324 [==============================] - 0s 101us/sample - loss: 0.0148 - mean_absolute_error: 0.0588 - mean_squared_error: 0.0092 - val_loss: 0.0247 - val_mean_absolute_error: 0.0964 - val_mean_squared_error: 0.0191\n",
      "Epoch 27/50\n",
      "1324/1324 [==============================] - 0s 121us/sample - loss: 0.0144 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0089 - val_loss: 0.0231 - val_mean_absolute_error: 0.0920 - val_mean_squared_error: 0.0176\n",
      "Epoch 28/50\n",
      "1324/1324 [==============================] - 0s 98us/sample - loss: 0.0142 - mean_absolute_error: 0.0566 - mean_squared_error: 0.0088 - val_loss: 0.0222 - val_mean_absolute_error: 0.0896 - val_mean_squared_error: 0.0168\n",
      "Epoch 29/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0139 - mean_absolute_error: 0.0554 - mean_squared_error: 0.0085 - val_loss: 0.0210 - val_mean_absolute_error: 0.0863 - val_mean_squared_error: 0.0157\n",
      "Epoch 30/50\n",
      "1324/1324 [==============================] - 0s 110us/sample - loss: 0.0136 - mean_absolute_error: 0.0544 - mean_squared_error: 0.0083 - val_loss: 0.0203 - val_mean_absolute_error: 0.0842 - val_mean_squared_error: 0.0151\n",
      "Epoch 31/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0133 - mean_absolute_error: 0.0536 - mean_squared_error: 0.0081 - val_loss: 0.0198 - val_mean_absolute_error: 0.0823 - val_mean_squared_error: 0.0146\n",
      "Epoch 32/50\n",
      "1324/1324 [==============================] - 0s 104us/sample - loss: 0.0131 - mean_absolute_error: 0.0528 - mean_squared_error: 0.0079 - val_loss: 0.0196 - val_mean_absolute_error: 0.0818 - val_mean_squared_error: 0.0145\n",
      "Epoch 33/50\n",
      "1324/1324 [==============================] - 0s 88us/sample - loss: 0.0129 - mean_absolute_error: 0.0520 - mean_squared_error: 0.0078 - val_loss: 0.0182 - val_mean_absolute_error: 0.0774 - val_mean_squared_error: 0.0131\n",
      "Epoch 34/50\n",
      "1324/1324 [==============================] - 0s 124us/sample - loss: 0.0127 - mean_absolute_error: 0.0514 - mean_squared_error: 0.0077 - val_loss: 0.0174 - val_mean_absolute_error: 0.0751 - val_mean_squared_error: 0.0124\n",
      "Epoch 35/50\n",
      "1324/1324 [==============================] - 0s 110us/sample - loss: 0.0125 - mean_absolute_error: 0.0508 - mean_squared_error: 0.0075 - val_loss: 0.0172 - val_mean_absolute_error: 0.0746 - val_mean_squared_error: 0.0123\n",
      "Epoch 36/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0122 - mean_absolute_error: 0.0499 - mean_squared_error: 0.0073 - val_loss: 0.0166 - val_mean_absolute_error: 0.0725 - val_mean_squared_error: 0.0118\n",
      "Epoch 37/50\n",
      "1324/1324 [==============================] - 0s 94us/sample - loss: 0.0121 - mean_absolute_error: 0.0495 - mean_squared_error: 0.0073 - val_loss: 0.0159 - val_mean_absolute_error: 0.0702 - val_mean_squared_error: 0.0111\n",
      "Epoch 38/50\n",
      "1324/1324 [==============================] - 0s 84us/sample - loss: 0.0119 - mean_absolute_error: 0.0489 - mean_squared_error: 0.0071 - val_loss: 0.0161 - val_mean_absolute_error: 0.0709 - val_mean_squared_error: 0.0113\n",
      "Epoch 39/50\n",
      "1324/1324 [==============================] - 0s 85us/sample - loss: 0.0118 - mean_absolute_error: 0.0484 - mean_squared_error: 0.0070 - val_loss: 0.0151 - val_mean_absolute_error: 0.0674 - val_mean_squared_error: 0.0104\n",
      "Epoch 40/50\n",
      "1324/1324 [==============================] - 0s 87us/sample - loss: 0.0116 - mean_absolute_error: 0.0478 - mean_squared_error: 0.0069 - val_loss: 0.0150 - val_mean_absolute_error: 0.0668 - val_mean_squared_error: 0.0103\n",
      "Epoch 41/50\n",
      "1324/1324 [==============================] - 0s 93us/sample - loss: 0.0115 - mean_absolute_error: 0.0476 - mean_squared_error: 0.0069 - val_loss: 0.0149 - val_mean_absolute_error: 0.0670 - val_mean_squared_error: 0.0104\n",
      "Epoch 42/50\n",
      "1324/1324 [==============================] - 0s 88us/sample - loss: 0.0114 - mean_absolute_error: 0.0473 - mean_squared_error: 0.0068 - val_loss: 0.0145 - val_mean_absolute_error: 0.0654 - val_mean_squared_error: 0.0100\n",
      "Epoch 43/50\n",
      "1324/1324 [==============================] - 0s 107us/sample - loss: 0.0113 - mean_absolute_error: 0.0471 - mean_squared_error: 0.0068 - val_loss: 0.0143 - val_mean_absolute_error: 0.0645 - val_mean_squared_error: 0.0098\n",
      "Epoch 44/50\n",
      "1324/1324 [==============================] - 0s 100us/sample - loss: 0.0111 - mean_absolute_error: 0.0464 - mean_squared_error: 0.0067 - val_loss: 0.0143 - val_mean_absolute_error: 0.0647 - val_mean_squared_error: 0.0099\n",
      "Epoch 45/50\n",
      "1324/1324 [==============================] - 0s 87us/sample - loss: 0.0110 - mean_absolute_error: 0.0462 - mean_squared_error: 0.0066 - val_loss: 0.0134 - val_mean_absolute_error: 0.0615 - val_mean_squared_error: 0.0090\n",
      "Epoch 46/50\n",
      "1324/1324 [==============================] - 0s 86us/sample - loss: 0.0109 - mean_absolute_error: 0.0456 - mean_squared_error: 0.0065 - val_loss: 0.0136 - val_mean_absolute_error: 0.0621 - val_mean_squared_error: 0.0092\n",
      "Epoch 47/50\n",
      "1324/1324 [==============================] - 0s 83us/sample - loss: 0.0108 - mean_absolute_error: 0.0454 - mean_squared_error: 0.0064 - val_loss: 0.0131 - val_mean_absolute_error: 0.0606 - val_mean_squared_error: 0.0088\n",
      "Epoch 48/50\n",
      "1324/1324 [==============================] - 0s 83us/sample - loss: 0.0106 - mean_absolute_error: 0.0448 - mean_squared_error: 0.0064 - val_loss: 0.0133 - val_mean_absolute_error: 0.0617 - val_mean_squared_error: 0.0090\n",
      "Epoch 49/50\n",
      "1324/1324 [==============================] - 0s 77us/sample - loss: 0.0106 - mean_absolute_error: 0.0449 - mean_squared_error: 0.0064 - val_loss: 0.0129 - val_mean_absolute_error: 0.0597 - val_mean_squared_error: 0.0087\n",
      "Epoch 50/50\n",
      "1324/1324 [==============================] - 0s 90us/sample - loss: 0.0105 - mean_absolute_error: 0.0449 - mean_squared_error: 0.0064 - val_loss: 0.0138 - val_mean_absolute_error: 0.0636 - val_mean_squared_error: 0.0096\n"
     ]
    }
   ],
   "source": [
    "movie = gen_movie(np.asarray(congest_pivot_np.reshape(NDATE*TIME_UNIT, ceil(NROWS/space_density), ceil(NCOLS/space_density)), order='C'), win_t=win_t, win_T=win_T)  \n",
    "\n",
    "data_x = movie[:, :win_t+win_T].astype('float32')\n",
    "data_y = movie[:, win_t+win_T].astype('float32')\n",
    "Max = max(data_x.max(), data_y.max())\n",
    "data_x /= Max # 归一化  \n",
    "data_y /= Max # 归一化 \n",
    "\n",
    "for batch in Batch_size:\n",
    "        train_x, train_y = data_x[:-N_SAMPLES_LAST_DAY], data_y[:-N_SAMPLES_LAST_DAY] # 训练集     \n",
    "        test_x, test_y = data_x[-N_SAMPLES_LAST_DAY:], data_y[-N_SAMPLES_LAST_DAY:] # 测试集\n",
    "        model = cnn_model(train_x.shape[1:])      \n",
    "        opt = keras.optimizers.Adam(learning_rate=4e-4)      \n",
    "        model.compile(loss='mse',      \n",
    "                optimizer=opt,      \n",
    "                metrics=['mae', 'mse'])      \n",
    "        batch_size = batch # 训练批次大小    \n",
    "        epochs = 50  # 训练轮数    \n",
    "        earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10) # 早停策略    \n",
    "        model.fit(train_x, train_y.reshape(-1, 100),      \n",
    "                batch_size=batch_size,      \n",
    "                epochs=epochs,       \n",
    "                validation_split=0.2,      \n",
    "                callbacks=[earlystop],      \n",
    "                shuffle=True) # 模型训练\n",
    "\n",
    "        predictions_test = model.predict(test_x, batch_size=512)    \n",
    "        mae_test = mean_absolute_error(predictions_test * Max, test_y.reshape(-1, 100) * Max)    \n",
    "        mse_test = mean_squared_error(predictions_test * Max, test_y.reshape(-1, 100) * Max)  \n",
    "        ex_records.append(f'batch:{batch}, MAE: {mae_test}, MSE: {mse_test}, RMSE: {np.sqrt(mse_test)}')\n",
    "        ex_data.append((mae_test, mse_test, np.sqrt(mse_test)))\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:32, MAE: 0.9054922461509705, MSE: 2.3645567893981934, RMSE: 1.537711501121521\n",
      "batch:64, MAE: 0.848264753818512, MSE: 2.2004141807556152, RMSE: 1.4833793640136719\n",
      "batch:96, MAE: 0.9453760385513306, MSE: 2.505115509033203, RMSE: 1.5827556848526\n",
      "batch:128, MAE: 1.002068042755127, MSE: 2.751910448074341, RMSE: 1.658888339996338\n"
     ]
    }
   ],
   "source": [
    "for record in ex_records:\n",
    "    print(record)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
