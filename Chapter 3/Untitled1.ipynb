{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8096508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np   \n",
    "# 拉格朗日插值        \n",
    "from scipy.interpolate import lagrange  #scipy.interpolate是内置工具包        \n",
    "def ploy (s,n,k=5):        \n",
    "    y=s[list(range(n-k,n))+list(range(n+1,n+1+k))] #取出插值位置前后k个数据  \n",
    "    y=y[y.notnull()]  #剔除空值      \n",
    "    return lagrange(y.index,list(y))(n)  \n",
    "traj = pd.read_csv('DATASET-A.csv', header=None, usecols=[2,3,4]).iloc[:15]  \n",
    "traj.columns = ['timestamp', 'lon', 'lat']  \n",
    "traj['time_interval'] = traj['timestamp'] - traj['timestamp'].shift(1)    \n",
    "index = traj[traj['time_interval'] >=6].index.to_list()    \n",
    "for i in index:    \n",
    "    timestamp = traj['timestamp'].loc[i-1] + 3    \n",
    "    insertRow = pd.DataFrame([[np.nan, np.nan, timestamp]], columns=['lon', 'lat', 'timestamp'])    \n",
    "    traj = pd.concat([traj[:i], insertRow, traj[i:]], ignore_index=True)    \n",
    "    traj['lon'][i]=ploy(traj['lon'],i)    \n",
    "    traj['lat'][i]=ploy(traj['lat'],i)    \n",
    "traj = traj.drop(['time_interval'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21532ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utm import *    \n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "time1 = '20161101 08:00:00'    \n",
    "time2 = '20161101 09:00:00'\n",
    "stamp1 = time.mktime(time.strptime(time1, \"%Y%m%d %H:%M:%S\")) \n",
    "stamp2 = time.mktime(time.strptime(time2, \"%Y%m%d %H:%M:%S\"))\n",
    "df = pd.read_csv('DATASET-A.csv', header=None)  \n",
    "df.columns=['driver_id', 'order_id', 'timestamp', 'lon', 'lat']\n",
    "# 转换为utc+8时区\n",
    "df.timestamp = df.timestamp + 8 * 3600\n",
    "df = df[(df['timestamp'] >= stamp1) & (df['timestamp'] < stamp2)].reset_index(drop=True)\n",
    "print (df.info())\n",
    "print (df.head(10))\n",
    "\n",
    "from osgeo import osr\n",
    "wgs84 = osr.SpatialReference()\n",
    "wgs84.ImportFromEPSG(4326)  #wgs-84坐标系\n",
    "inp = osr.SpatialReference()\n",
    "inp.ImportFromEPSG(3857)    #Pseudo-Mercator坐标系\n",
    "# 定义坐标转换\n",
    "transformation = osr.CoordinateTransformation(wgs84, inp)\n",
    "#转换坐标\n",
    "xy = df[['lon', 'lat']].apply(lambda x: transformation.TransformPoint(x[0], x[1])[:2], axis=1) \n",
    "# xy为一个list，每一个元素为一个tuple\n",
    "# 转换为dataframe中的两列\n",
    "df['x'] = [x[0] for x in xy]\n",
    "df['y'] = [x[1] for x in xy]\n",
    "\n",
    "#时间窗划分 \n",
    "time_interval=600 #时间窗长度  \n",
    "df['time_id'] = df['timestamp'].apply(lambda x: (x - stamp1)//time_interval) #生成时间窗索引  \n",
    "#空间网格划分    \n",
    "left = df['x'].min() #计算左边界    \n",
    "up = df['y'].max() #计算上边界    \n",
    "interval=70 #网格单元大小    \n",
    "df['rowid'] = df['y'].apply(lambda x: (up - x) // interval).astype('int') #计算横向索引    \n",
    "df['colid'] = df['x'].apply(lambda x: (x - left) // interval).astype('int')#计算纵向索引 \n",
    "\n",
    "df = df.sort_values(by=['driver_id', 'order_id', 'timestamp']).reset_index(drop=True)  \n",
    "# 将订单id，下移一行，用于判断相邻记录是否属于同一订单  \n",
    "df['orderFlag'] = df['order_id'].shift(1)  \n",
    "df['identi'] = (df['orderFlag']==df['order_id'])  \n",
    "# 将坐标、时间戳下移一行，从而匹配相邻轨迹点  \n",
    "df['x1'] = df['x'].shift(1)  \n",
    "df['y1'] = df['y'].shift(1)  \n",
    "df['timestamp1'] = df['timestamp'].shift(1)\n",
    "df = df[df['identi']==True]   #将不属于同一订单的轨迹点对删去  \n",
    "dist = np.sqrt(np.square((df['x'].values-df['x1'].values)) + np.square((df['y'].values-df['y1'].values)))    # 计算相邻轨迹点之间的距离    \n",
    "time = df['timestamp'].values - df['timestamp1'].values   # 计算相邻轨迹点相差时间  \n",
    "df['speed'] = dist / time    # 计算速度    \n",
    "df = df.drop(columns=['x1', 'y1', 'orderFlag', 'timestamp1', 'identi'])   # 删去无用列 \n",
    "\n",
    "df['speed1'] = df.speed.shift(1)                 # 将速度下移一行\n",
    "df['timestamp1'] = df.timestamp.shift(1)         # 将时间下移一行\n",
    "df['identi'] = df.order_id.shift(1)              # 将订单号下移一行\n",
    "df = df[df.order_id==df.identi]                  # 去除两个订单分界点数据\n",
    "df.loc[:, 'acc'] = (df.speed1.values - df.speed.values) / (df.timestamp1.values - df.timestamp.values)  #计算加速度\n",
    "df = df.drop(columns=['speed1', 'timestamp1', 'identi'])  #删除临时字段\n",
    "\n",
    "orderGrouped = df.groupby(['rowid', 'colid','time_id', 'order_id'])  # 基于时空网格与轨迹id进行分组   \n",
    "# 网格平均车速  \n",
    "grouped_speed = orderGrouped.speed.mean().reset_index()  \n",
    "grouped_speed = grouped_speed.groupby(['rowid', 'colid', 'time_id'])  \n",
    "grid_speed = grouped_speed.speed.mean()  \n",
    "grid_speed = grid_speed.clip(grid_speed.quantile(0.05), grid_speed.quantile(0.95))#去除异常值  \n",
    "grid_speed.head()  \n",
    "\n",
    "# 网格平均加速度\n",
    "gridGrouped = df.groupby(['rowid', 'colid','time_id'])\n",
    "grid_acc = gridGrouped.acc.mean()  \n",
    "grid_acc.head() \n",
    "\n",
    "# 网格流量  \n",
    "grouped_volume = orderGrouped.speed.last().reset_index()  \n",
    "grouped_volume = grouped_volume.groupby(['rowid', 'colid', 'time_id'])  \n",
    "grid_volume = grouped_volume['speed'].size()  \n",
    "grid_volume = grid_volume.clip(grid_volume.quantile(0.05), grid_volume.quantile(0.95))  \n",
    "grid_volume.head() \n",
    "\n",
    "# 网格车速标准差  \n",
    "grid_v_std = gridGrouped.speed.std()  \n",
    "grid_v_std.head()  \n",
    "\n",
    "# 网格平均停车次数  \n",
    "stopNum = gridGrouped.speed.agg(lambda x: (x==0).sum())  \n",
    "grid_stop = pd.concat((stopNum, grid_volume), axis=1)  \n",
    "grid_stop['stopNum'] = stopNum.values / grid_volume.values  \n",
    "grid_stop = grid_stop['stopNum']  \n",
    "grid_stop = grid_stop.clip(0,grid_stop.quantile(0.95))  \n",
    "grid_stop.head()  \n",
    "\n",
    "feature = pd.concat([grid_speed, grid_acc, grid_volume, grid_v_std, grid_stop], axis=1).reset_index()  \n",
    "feature.columns = ['rowid', 'colid', 'time_id', 'aveSpeed', 'gridAcc', 'volume', 'speed_std', 'stopNum']  \n",
    "feature.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbdda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv('DATASET-B.csv')\n",
    "data_speed = data[(data['date']==20161101) & (data['time_id']==0)]['aveSpeed']\n",
    "statistics = data_speed.describe()#保存基本统计量      \n",
    "statistics.loc['range']=statistics.loc['max']-statistics.loc['min']#极差 \n",
    "statistics.loc['var']=statistics.loc['std']/statistics.loc['mean']#变异系数  \n",
    "statistics.loc['dis']=statistics.loc['75%']-statistics.loc['25%']#四分位数间距 \n",
    "print (statistics)\n",
    "statistics.to_csv('statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5965a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('DATASET-B.csv')\n",
    "data_vol = data[data['time_id']==50].groupby(['date'])['volume'].sum()\n",
    "df = pd.DataFrame(data_vol)\n",
    "df = df.reset_index(drop=False)\n",
    "from datetime import datetime\n",
    "df['day'] = df['date'].apply(lambda x: datetime.strptime(str(x), \"%Y%m%d\").weekday()+1)\n",
    "# weekday()函数返回值：周一为0，周日为6】"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prpPy36]",
   "language": "python",
   "name": "conda-env-prpPy36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
